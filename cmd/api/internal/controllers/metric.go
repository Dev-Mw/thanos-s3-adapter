package controllers

import (
	"bytes"
	"compress/gzip"
	"context"
	"encoding/json"
	"errors"
	"io"
	"math"
	"net/http"
	"net/url"
	"os"
	"strconv"
	"strings"
	"time"

	"github.com/Dev-Mw/thanos-s3-adapter/cmd/api/internal/logs"
	"github.com/Dev-Mw/thanos-s3-adapter/cmd/api/internal/models"
	"github.com/Dev-Mw/thanos-s3-adapter/cmd/api/internal/utils"
	"github.com/aws/aws-sdk-go-v2/aws"
	"github.com/aws/aws-sdk-go-v2/service/s3"

	"github.com/go-co-op/gocron"
)

var log = logs.GetLog()

func Run(config models.QueryConfig, metricChannel chan models.MetricChannel) {
	log.Info("Everything ready, executing programming...")
	// Run at boot
	go MetricRequest(config, metricChannel)

	// Run at schedule
	s := gocron.NewScheduler(time.UTC)
	s.Cron(config.Schedule).Do(MetricRequest, config, metricChannel)
	s.StartBlocking()
}

func getThanosStores(config models.QueryConfig) ([]interface{}, error) {
	log.Info("Requesting the available storages")
	var clusters []interface{}
	var body []byte
	var jsonResponse models.ThanosStoreResponse

	endPoint := config.EndpointAddress + "/api/v1/stores"
	log.Infof("END; %v", endPoint)
	response, err := http.Get(endPoint)
	if err != nil {
		msg := "Host error: " + err.Error()
		return nil, errors.New(msg)
	}
	if response.StatusCode != http.StatusOK {
		msg := "Request error " + strconv.Itoa(response.StatusCode)
		log.Error(msg)
		return nil, errors.New(msg)
	}
	defer response.Body.Close()

	body, err = io.ReadAll(response.Body)
	if err != nil {
		msg := "Read Body error: " + err.Error()
		log.Error(msg)
		return nil, errors.New(msg)
	}

	if err = json.Unmarshal(body, &jsonResponse); err != nil {
		msg := "Unmarshal error: " + err.Error()
		log.Error(msg)
		return nil, errors.New(msg)
	}
	log.Info("TOLOOO")
	for _, store := range jsonResponse.Data.Store {
		log.Info("HJJJOLOOO")
		for i, cluster := range store.LabelSets {
			minTime := time.Unix(store.MinTime/1000, 0).UTC().Format(time.RFC3339)
			maxTime := time.Unix(store.MaxTime/1000, 0).UTC().Format(time.RFC3339)
			log.Infof("%v - Cluster information found: %s from %v to %v", i+1, cluster.ClusterID, minTime, maxTime)
			clusters = append(clusters, cluster.ClusterID)
		}
	}

	return clusters, nil
}

func MetricRequest(config models.QueryConfig, metricChannel chan models.MetricChannel) {
	endPoint := config.EndpointAddress + "/api/v1/query_range"

	// Default time range
	if config.StartDate == "" && config.EndDate == "" {
		log.Warn("A defined time range was not found, one is generated by default...")
		intBackTime, err := strconv.Atoi(os.Getenv("BACK_TIME"))
		if err != nil {
			log.Errorf("BACK_TIME is not valid integer: %s", err.Error())
			log.Exit(1)
		}
		config.EndDate = time.Now().UTC().Add(-time.Hour * time.Duration(intBackTime)).Format("2006-01-02T15:00:00Z")
		config.StartDate = time.Now().UTC().Add(-time.Second * time.Duration(config.Interval)).Add(-time.Hour * time.Duration(intBackTime)).Format("2006-01-02T15:00:00Z")
		msg := "Default time range: " + config.StartDate + " - " + config.EndDate
		log.Info(msg)
	}

	// Generate time intervals
	intervals, err := utils.DatesValidation(config.StartDate, config.EndDate, config.Interval)
	if err != nil {
		log.Error(err.Error() + ", abort the next steps...")
		return
	}

	// Check if the query contains reserved words
	clusters := []interface{}{"all-clusters"}
	if strings.Contains(config.Query, "CLUSTER_NAME") {
		clusters, err = getThanosStores(config)
		if err != nil {
			log.Error(err.Error() + ", abort the next steps...")
			return
		}
	}

	// Generate the query
	for _, interval := range intervals {
		var body []byte

		log.Infof("Request metric for range: %s", interval)

		endRangeDate := interval[1].(string)
		startRangeDate := interval[0].(string)
		for _, cluster := range clusters {
			start := time.Now()

			// Set the query parameters
			data := url.Values{}
			data.Add("query", strings.ReplaceAll(config.Query, "CLUSTER_NAME", cluster.(string)))
			data.Add("step", config.QueryStep)
			data.Add("dedup", "true")
			data.Add("start", startRangeDate)
			data.Add("end", endRangeDate)

			// Request the metric
			resp, err := http.PostForm(endPoint, data)
			if err != nil {
				log.Errorf("[%s] -> Host error: %s, abort the next steps...", cluster.(string), err.Error())
				return
			}

			// Log the request
			decodedValue, err := url.QueryUnescape(data.Encode())
			if err != nil {
				log.Errorf("[%s] -> Url error: %s", cluster.(string), err.Error())
			}
			log.Infof("[%s] -> Requested: %+v With values: %s", cluster.(string), resp.Request.URL, decodedValue)

			// Read the response
			body, _ = io.ReadAll(resp.Body)
			resp.Body.Close()

			if resp.StatusCode != http.StatusOK {
				log.Warningf("[%s] -> Request error <[%v]> %s, abort the next steps...", cluster.(string), resp.StatusCode, string(body))
				return
			}

			// Send the response to formatter
			log.Infof("[%s] -> Send metric to channel...", cluster.(string))
			metricChannel <- models.MetricChannel{Body: body, Config: config, Cluster: cluster.(string), StartTimeUnix: startRangeDate, EndTimeUnix: endRangeDate}

			// Log the elapsed time
			elapsed := time.Since(start)
			log.Printf("[%s] -> Request took %s", cluster.(string), elapsed)
		}
	}
	log.Info("Metric Request Done...")
}

func SeriesFormat(metrics chan models.MetricChannel, series chan models.SeriesChannel) {
	log.Info("Series Format Ready...")
	for pkg := range metrics {
		var byteData bytes.Buffer
		var jsonResponse models.ThanosMetricResponse
		var totalSeries int64
		var ds = time.Now().UTC().Format(time.RFC3339)

		err := json.Unmarshal(pkg.Body, &jsonResponse)
		if err != nil {
			log.Error("Unmarshal error: " + err.Error())
			log.ExitFunc(0)
		}

		for _, v := range jsonResponse.Data.Result {
			var jsonData models.JSONSchema
			var formatValues [][]interface{}
			for _, metricValue := range v.Values {
				sec, dec := math.Modf(metricValue[0].(float64))
				timeUnix := time.Unix(int64(sec), int64(dec*(1e9))).Unix()

				value := []interface{}{
					timeUnix,
					metricValue[1].(string),
				}
				formatValues = append(formatValues, value)
			}
			jsonData.Start = pkg.StartTimeUnix
			jsonData.End = pkg.EndTimeUnix
			jsonData.Metric = v.Metric
			jsonData.Interval = strconv.Itoa(pkg.Config.Interval)
			jsonData.Step = pkg.Config.QueryStep
			jsonData.Values = formatValues
			jsonData.Expression = strings.ReplaceAll(pkg.Config.Query, "CLUSTER_NAME", pkg.Cluster)
			jsonData.Ds = ds

			data, err := json.Marshal(jsonData)
			if err != nil {
				log.Error("Marshal error: " + err.Error())
				log.ExitFunc(0)
			}
			if data != nil {
				byteData.WriteString(string(data) + "\n")
			}
			totalSeries++
		}

		if jsonResponse.Data.Result != nil && byteData.Len() > 0 {
			log.Infof("[%s] -> Series found: %v", pkg.Cluster, totalSeries)
			log.Infof("[%s] -> Bytes formatted: %v", pkg.Cluster, byteData.Len())
		} else {
			log.Warningf("[%s] -> No series found, check URL", pkg.Cluster)
			log.Warningf("[%s] -> The following steps will not be executed", pkg.Cluster)
		}

		// Send the formatted data
		extractTime, _ := time.Parse(time.RFC3339, pkg.StartTimeUnix)
		series <- models.SeriesChannel{ByteData: byteData, Config: pkg.Config, ExtractTime: extractTime, Cluster: pkg.Cluster}
	}
}

func SeriesStore(awsConfig aws.Config, series chan models.SeriesChannel) {
	log.Info("Series Store Ready...")
	for pkg := range series {
		// Compress Data
		var compressData bytes.Buffer

		zipper := gzip.NewWriter(&compressData)
		n, err := zipper.Write(pkg.ByteData.Bytes())
		if err != nil {
			log.Errorf("[%s] -> Error to compress the data: %v", pkg.Cluster, err)
			log.ExitFunc(0)
		}
		log.Infof("[%s] -> Compressed bytes: %v", pkg.Cluster, n)

		if err := zipper.Close(); err != nil {
			log.Warningf("[%s] -> Error with zipper: %v", pkg.Cluster, err)
		}

		// Define file name
		datetime := strings.Split(pkg.ExtractTime.Format("2006-01-02 15:04:05"), " ")
		dateStr := strings.Split(datetime[0], "-")
		timeStr := strings.Split(datetime[1], ":")

		year := dateStr[0]
		month := dateStr[1]
		day := dateStr[2]

		hour := timeStr[0]

		fileName := pkg.Config.MetricName + "/" + year + "/" + month + "/" + day + "/" + hour + "/" + pkg.Cluster + ".json.gz"

		// Upload to S3
		client := s3.NewFromConfig(awsConfig)
		_, err = client.PutObject(context.TODO(),
			&s3.PutObjectInput{
				Bucket: aws.String(pkg.Config.MetricBucket),
				Key:    aws.String(fileName),
				Body:   bytes.NewReader(compressData.Bytes()),
			},
		)

		if err != nil {
			log.Warningf("[%s] -> Error to load file: %v", pkg.Cluster, err)
		} else {
			log.Infof("[%s] -> File uploaded successfully [Bucket: %v, Folder/File: %v]", pkg.Cluster, pkg.Config.MetricBucket, fileName)
		}
	}
}
